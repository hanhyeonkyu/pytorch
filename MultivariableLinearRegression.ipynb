{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27daddfa-400d-48ae-968a-e27c9c492985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b3875b-dec5-4ff0-bd46-1863b00ed1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
      "Epoch 10000/100000 w1: 0.888 w2: 0.464 w3: 0.658 b: 0.020 Cost: 0.271221\n",
      "Epoch 20000/100000 w1: 0.933 w2: 0.466 w3: 0.612 b: 0.028 Cost: 0.227062\n",
      "Epoch 30000/100000 w1: 0.960 w2: 0.478 w3: 0.574 b: 0.036 Cost: 0.203359\n",
      "Epoch 40000/100000 w1: 0.980 w2: 0.488 w3: 0.544 b: 0.042 Cost: 0.188757\n",
      "Epoch 50000/100000 w1: 0.996 w2: 0.496 w3: 0.521 b: 0.048 Cost: 0.179741\n",
      "Epoch 60000/100000 w1: 1.008 w2: 0.502 w3: 0.502 b: 0.053 Cost: 0.174168\n",
      "Epoch 70000/100000 w1: 1.018 w2: 0.507 w3: 0.488 b: 0.058 Cost: 0.170691\n",
      "Epoch 80000/100000 w1: 1.025 w2: 0.510 w3: 0.477 b: 0.062 Cost: 0.168530\n",
      "Epoch 90000/100000 w1: 1.031 w2: 0.513 w3: 0.468 b: 0.066 Cost: 0.167169\n",
      "Epoch 100000/100000 w1: 1.036 w2: 0.516 w3: 0.461 b: 0.070 Cost: 0.166299\n",
      "tensor([[151.5023],\n",
      "        [184.6397],\n",
      "        [180.6607],\n",
      "        [196.1304],\n",
      "        [141.9783]], grad_fn=<AddBackward0>)\n",
      "tensor([[152.],\n",
      "        [185.],\n",
      "        [180.],\n",
      "        [196.],\n",
      "        [142.]])\n",
      "tensor([[ 0.4977],\n",
      "        [ 0.3603],\n",
      "        [-0.6607],\n",
      "        [-0.1304],\n",
      "        [ 0.0217]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# if restart, get same result. random seed set\n",
    "torch.manual_seed(1)\n",
    "# train data\n",
    "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
    "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
    "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
    "# W, b set\n",
    "w1 = torch.zeros(1, requires_grad=True)\n",
    "w2 = torch.zeros(1, requires_grad=True)\n",
    "w3 = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer set\n",
    "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
    "nb_epochs = 100000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # hypothesis\n",
    "    hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
    "    # cost function\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    # cost -> H(x) enhance\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    # print log\n",
    "    if epoch % 10000 == 0:\n",
    "        print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()\n",
    "        ))\n",
    "# trained hypothesis\n",
    "y = w1 * x1_train + w2 * x2_train + w3 * x3_train + b\n",
    "print(y)\n",
    "print(y_train)\n",
    "print(y_train-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3acb0d63-bfe6-4b11-a18c-b2f6a703e7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 1])\n",
      "Epoch    0/10000 hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
      "Epoch 1000/10000 hypothesis: tensor([153.8955, 184.8841, 176.6536, 198.0995, 141.2951]) Cost: 3.941853\n",
      "Epoch 2000/10000 hypothesis: tensor([153.7204, 184.7364, 177.3512, 197.6782, 141.4043]) Cost: 2.643340\n",
      "Epoch 3000/10000 hypothesis: tensor([153.5477, 184.6475, 177.8806, 197.3408, 141.5250]) Cost: 1.806990\n",
      "Epoch 4000/10000 hypothesis: tensor([153.3855, 184.5969, 178.2860, 197.0692, 141.6459]) Cost: 1.257653\n",
      "Epoch 5000/10000 hypothesis: tensor([153.2379, 184.5707, 178.5994, 196.8493, 141.7604]) Cost: 0.891409\n",
      "Epoch 6000/10000 hypothesis: tensor([153.1065, 184.5599, 178.8437, 196.6707, 141.8653]) Cost: 0.644614\n",
      "Epoch 7000/10000 hypothesis: tensor([152.9913, 184.5584, 179.0357, 196.5250, 141.9590]) Cost: 0.476993\n",
      "Epoch 8000/10000 hypothesis: tensor([152.8914, 184.5623, 179.1876, 196.4059, 142.0414]) Cost: 0.362508\n",
      "Epoch 9000/10000 hypothesis: tensor([152.8054, 184.5690, 179.3087, 196.3082, 142.1130]) Cost: 0.284021\n",
      "Epoch 10000/10000 hypothesis: tensor([152.7321, 184.5770, 179.4058, 196.2279, 142.1747]) Cost: 0.230068\n",
      "tensor([[152.7320],\n",
      "        [184.5771],\n",
      "        [179.4059],\n",
      "        [196.2278],\n",
      "        [142.1747]], grad_fn=<AddBackward0>)\n",
      "tensor([[152.],\n",
      "        [185.],\n",
      "        [180.],\n",
      "        [196.],\n",
      "        [142.]])\n",
      "tensor([[-0.7320],\n",
      "        [ 0.4229],\n",
      "        [ 0.5941],\n",
      "        [-0.2278],\n",
      "        [-0.1747]], grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# above things need change vector & matrix way\n",
    "# vector & matrix way\n",
    "# train data\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  80], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "# check shape\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "# W, b set\n",
    "W = torch.zeros((3, 1), requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer\n",
    "optimizer = optim.SGD([W, b], lr=1e-5)\n",
    "nb_epochs = 10000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # hypothesis\n",
    "    hypothesis = x_train.matmul(W) + b\n",
    "    # cost function\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    # cost -> hypothesis enhance\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        print('Epoch {:4d}/{} hypothesis: {} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
    "        ))\n",
    "# trained hypothesis\n",
    "y = x_train.matmul(W) + b\n",
    "print(y)\n",
    "print(y_train)\n",
    "print(y_train-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97111d36-a41e-4eb8-89ef-0ca79cc50cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
